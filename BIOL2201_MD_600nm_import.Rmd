---
title: "Import and fit microbial plate growth data"
author: "Maximilian Berthold, Douglas A. Campbell"
date: "`r format(Sys.Date())`"
output:
  html_document:
    df_print: paged
    code_folding: hide
---

This .Rmd imports Molecular Device Fluorescence well plate files, generated using a single wavelength protocol, with one or more plates in the file.
The size of the well plate does not matter; the import creates columns for RowColumn LetterNumber (A01 etc.) for the largest plate type in the list of files.
Import of smaller plate types results in NA in the non-existent RowColumn for that plate.

```{r load libraries, echo=FALSE, message = FALSE, warning = FALSE} 
# libraries; Note check actual dependencies
library(tidyverse) #core tidyverse packages
library(lubridate) #tidyverse dates
library(googledrive) #accessing googledrive
library(googlesheets4) #accessing googlesheets
library(minpack.lm) #curve fitting
library(broom) #tidy model outputs

```

```{r variable names for file import & processing MOLECULAR DEVICES}
Project <- "BIOL2201"
DayGroup = "THURS"
DayBench = "B1"


#set variables for file import & processing
DataPathMD <- file.path("RawData", "Single600Files", fsep = .Platform$file.sep)
file_id <- ".txt"

DataOut <- "ProcessData"

FileEncodeMD <- "UTF-16LE" 
DelimiterMD <- "\t"
HeaderRowsMD <- 2

MetaDataURL <- "https://docs.google.com/spreadsheets/d/1FTKwYlJXd0ze9WwVXCvtwe5qkpN3_HNbeeM3hg7xnrI/edit#gid=0"
```

Load MetaData from GoogleSheet
```{r read metadata}
#deauthorizes access to googlesheet
gs4_deauth()

#read contents of MetaData from GoogleSheet

MetaData20 <- read_sheet(MetaDataURL, sheet = "20")
MetaData37 <- read_sheet(MetaDataURL, sheet = "37")
MetaData <- rbind(MetaData20, MetaData37)

rm(MetaData20, MetaData37)

#correct values and variable names in MetaData
MetaData <- MetaData %>%
  mutate(Group = case_when(
    Day =="TUESDAY" ~"TUES",
    Day =="WEDNESDAY" ~"WED",
    Day == "THURSDAY" ~ "THURS"
  ), .after = Day) %>%
  mutate(MysteryID = as.factor(as.character(MysteryID))) %>%
  select(-c("Initials"))


```


```{r list data files}
OD_files <- list.files(path = DataPathMD, pattern = file_id, full.names = TRUE)

OD_files
#test for duplicate file names in chl_files
unique(duplicated(OD_files))

# guess encoding
guess_encoding(file = OD_files[1])
```

```{r read files, warning = FALSE, message = FALSE}
#"id" parameter of read_delim might replace read_delim_plus
#a read function using tidyverse::read_delim that skips a fixed number of header rows, and adds columns to the dataframe containing the filename and the file creation date time.
# 
read_delim_plus <- function(flnm, delimiter, headerrows, fileencode){read_delim(flnm, delim = delimiter,  col_names = TRUE,  skip = headerrows, escape_double = FALSE,  locale = locale(encoding = fileencode), trim_ws = TRUE) %>%
    mutate(Filename = flnm)
  }


OD_data <- OD_files %>%
  map_df(~read_delim_plus(flnm = ., delimiter = DelimiterMD,  headerrows = HeaderRowsMD,  fileencode = FileEncodeMD))

```

```{r tidy OD_data}
OD <- OD_data %>%
  select(-c("...1", "Temperature(Â¡C)", "...27")) %>%
  filter(!is.na(A1))  %>%
  separate(Filename, into = c("Path1", "Path2", "DDMMYYYY", "HHMM","Group", "Bench", "Temp_C", "txt"), sep = "([\\/\\_\\.])", remove = FALSE) %>%
  select(-c("Path1", "Path2", "txt")) %>%
  relocate(c("DDMMYYYY", "HHMM","Group", "Bench", "Temp_C")) %>%
  unite(DDMMYYYY_HHMM,  DDMMYYYY:HHMM, sep = "_", remove = TRUE) %>%
  mutate(DDMMYYYY_HHMM = dmy_hm(DDMMYYYY_HHMM)) %>%
  mutate(Temp_C = as.numeric(Temp_C))

#3 rows of data to average from each well measurement

OD <- OD %>%
  group_by(DDMMYYYY_HHMM, Group, Bench, Temp_C, Filename) %>%
  summarize(across(A1:D6, mean)) %>%
  ungroup()
  
```


```{r E_hours}
OD <- OD %>%
  group_by(Group, Bench, Temp_C) %>%
  mutate(E_hours =  as.numeric((DDMMYYYY_HHMM - min(DDMMYYYY_HHMM))) / 3600, .after = DDMMYYYY_HHMM) %>%
  ungroup()
```

```{r OD test plot}
OD %>% ggplot() +
  geom_point(aes(x = E_hours, y = A1)) + 
  facet_grid(rows = vars(Group), cols = vars(Bench, Temp_C)) +
   scale_x_continuous(sec.axis = sec_axis(~ . , name = sym("Bench"), breaks = NULL, labels = NULL)) +
  scale_y_continuous(sec.axis = sec_axis(~ . , name = sym("Group"), breaks = NULL, labels = NULL)) +
  theme_bw()

OD %>% ggplot() +
  geom_point(aes(x = E_hours, y = A1)) + 
  facet_grid(rows = vars(Group), cols = vars(Bench, Temp_C)) +
   scale_x_continuous(sec.axis = sec_axis(~ . , name = sym("Bench"), breaks = NULL, labels = NULL)) +
  scale_y_continuous(sec.axis = sec_axis(~ . , name = sym("Group"), breaks = NULL, labels = NULL)) +
  theme_bw()

```



```{r long format}
OD_long <- OD %>%
  pivot_longer(cols = -c(DDMMYYYY_HHMM, E_hours, Group, Bench, Temp_C, Filename), names_to = "Well", values_to = "OD_600") %>%
  separate(Well, into = c("Row", "Col"), sep = 1, remove = FALSE)

```


```{r logOD}
OD_long <- OD_long %>%
  mutate(logOD_600 = log(OD_600))
```

```{r OD facet plot}
OD_long %>% 
  filter(Temp_C == 20,
         Group == DayGroup) %>%
  ggplot() +
  geom_point((aes(x = E_hours, y = logOD_600, colour = Row))) + 
  facet_grid(rows = vars(Bench), cols = vars(Col)) +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = "Column", breaks = NULL, labels = NULL)) +
  scale_y_continuous(sec.axis = sec_axis(~ . , name = sym("Bench"), breaks = NULL, labels = NULL)) +
  labs(title = DayGroup) +
  theme_bw()

OD_long %>% 
  filter(Temp_C == 20,
         Group == DayGroup,
         Bench == "B1") %>%
  ggplot() +
  geom_point((aes(x = E_hours, y = OD_600))) + 
  facet_grid(rows = vars(Row), cols = vars(Col)) +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = " Plate Column", breaks = NULL, labels = NULL)) +
  scale_y_continuous(sec.axis = sec_axis(~ . , name = sym("Plate Row"), breaks = NULL, labels = NULL)) +
  theme_bw()

ggsave(filename = file.path("Plots", "WellPlateExample.png") )
```

Merge OD_long with MetaData
```{r left_join OD_long with MetaData}

OD_meta <- left_join(x = OD_long, y = MetaData, by = c("Group", "Bench", "Temp_C", "Well"), keep = FALSE)

```

```{r filter out blank data rows}
OD_meta <- OD_meta %>%
  filter(MysteryID != "TSB",
         MysteryID != "BLANK")
```

```{r save OD_meta, echo=FALSE}
saveRDS(OD_meta, file.path(DataOut, 
paste(Project, "OD_meta.Rds", sep = "_"), fsep = .Platform$file.sep))
```

```{r export bench specific csv}
DayGroup = "THURS"
DayBench = "B1"

OD_meta %>%
  filter(Group == DayGroup) %>%
  filter(Bench == DayBench) %>%
  select(-c(Day, Media_mL, Innoc_mL, Row, Col, logOD_600)) %>%
  pivot_wider(names_from = c(Well, MysteryID), values_from = c(OD_600)) %>%
  arrange(Temp_C) %>%
  write_csv(., file = file.path("ProcessData", paste(Project, "_", DayGroup,"_", DayBench, "_OD600", ".csv", sep = "")))



  #working on bulk write of nested dataframe to .csv, instead of filtering
  
  # test <- 
  #   
  #   OD_meta |>
  # select(-c(Media_mL, Innoc_mL, Row, Col, logOD_600)) %>%
  # pivot_wider(names_from = c(Well, MysteryID), values_from = c(OD_600)) %>%
  # arrange(Temp_C) %>%
  # nest(.by = c(Group)) %>%
  # walk2(.$data, .$Group, ~ write_csv(.x, file = paste0(.y, ".csv")))  
  # 
  # 
  # walk2(test$data, test$Bench, ~ write_csv(.x, file = paste0(.y, ".csv")))


  
```

Implement Growth Curve fits well by well.
Define equations as functions.
x will be taken from 'E_days' when we run the fit.
```{r logistic_eqn}
LogisticEqn <-  function(x, Pmax, Mu, Intercept){(Pmax*Intercept*exp(Mu*x))/(Pmax + (Intercept*(exp(Mu*x)-1)))
}

possibnlSLM = possibly(.f = nlsLM, otherwise = NULL)
```

Fit logistic growth trajectories using nest purrr:map & broom::augment using start, lower & upper settings extracted from each nest on the fly.
Extracting nest-specific start, lower & upper settings from each nest on the fly may be necessary if the 'nests' contain diverse data patterns that fail to fit with generic start, lower & upper parameters extracted from the entire dataset
```{r growth well fits}
OD_nest <- OD_meta %>%
  filter(Group == DayGroup) %>%
  filter(Bench == DayBench) %>%
  nest(data = c(DDMMYYYY_HHMM, Filename, E_hours, OD_600, logOD_600))

OD_nest <- OD_nest %>%
  mutate(ExpInit_h = as.numeric(map(data, ~((.$logOD_600[2]) - (.$logOD_600[1]))/.$E_hours[2]))) %>%
  mutate(FitLog = map(data, ~possibnlSLM(OD_600 ~ LogisticEqn(x = E_hours, Intercept, Mu, Pmax),
                                         data = .x,
                                         start = list(Intercept = min(.$OD_600, na.rm = TRUE), Mu = 0.1, Pmax = max(.$OD_600, na.rm = TRUE))
                                         )
  ),
  TidiedLog = map(FitLog, tidy),
  PredictLog = map(FitLog, augment)
  )

OD_nest %>%
  unnest(PredictLog) %>%
  ggplot() + 
  geom_point(aes(x = E_hours, y = OD_600)) + 
  geom_line(aes(x = E_hours, y =  `.fitted`)) +
  facet_grid(col = vars(MysteryID, Well), rows = vars(Temp_C)) +
   scale_x_continuous(sec.axis = sec_axis(~ . , name = sym("MysteryID"), breaks = NULL, labels = NULL)) +
  scale_y_continuous(sec.axis = sec_axis(~ . , name = sym("Temp_c"), breaks = NULL, labels = NULL)) +
  labs(title = sym(DayGroup), subtitle = sym(DayBench)) +
  theme_bw()

Mu_est <- OD_nest %>% 
  dplyr::select(-c(data, FitLog, PredictLog)) %>%
  unnest(TidiedLog) %>%
  select(-statistic) %>%
  pivot_wider(names_from = term, values_from = c(estimate:p.value))

Mu_est %>%
  ggplot() +
  geom_point(aes(x = MysteryID, y = estimate_Mu)) +
  geom_errorbar(aes(x = MysteryID, ymin = estimate_Mu - std.error_Mu,  ymax = estimate_Mu + std.error_Mu)) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  facet_grid(rows = vars(Temp_C)) +
  scale_y_continuous(sec.axis = sec_axis(~ . , name = sym("Temp_c"), breaks = NULL, labels = NULL)) +
   labs(title = sym(DayGroup), subtitle = sym(DayBench)) +
  theme_bw()

Mu_est %>%
  ggplot() +
  geom_point(aes(x = MysteryID, y = ExpInit_h)) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  facet_grid(rows = vars(Temp_C)) +
  scale_y_continuous(sec.axis = sec_axis(~ . , name = sym("Temp_c"), breaks = NULL, labels = NULL)) +
   labs(title = sym(DayGroup), subtitle = sym(DayBench)) +
  theme_bw()

Mu_est %>%
  ggplot() + 
  geom_point(aes(x = estimate_Mu, y = ExpInit_h, size = estimate_Pmax)) +
  coord_fixed(ratio = 1, xlim = c(0, 0.2), ylim = c(0, 0.2)) +
  facet_grid(cols = vars(Bench), rows = vars(Temp_C)) +
  labs(title = sym(DayGroup), subtitle = sym(DayBench)) +
  theme_bw()
  
```


Implement Growth Curve fits pool by pool of 4 rows together from one column.

Fit treatment specific logistic growth trajectories using nest purrr:map & broom::augment.
Using nest specific start, lower & upper settings extracted from each nest on the fly. may be necessary if the 'nests' contain diverse data patterns that fail to fit with generic start, lower & upper parameters extracted from the entire dataset
```{r growth pool fits}
OD_pool_nest <- OD_meta %>%
  filter(Group == DayGroup) %>%
  filter(Bench == DayBench) %>%
  nest(data = c(DDMMYYYY_HHMM, Well, Row, Filename, E_hours, OD_600, logOD_600))

OD_pool_nest <- OD_pool_nest %>%
  mutate(FitLog = map(data, ~possibnlSLM(OD_600 ~ LogisticEqn(x = E_hours, Intercept, Mu, Pmax),
                                         data = .x,
                                         start = list(Intercept = min(.$OD_600, na.rm = TRUE), Mu = 0.1, Pmax = max(.$OD_600, na.rm = TRUE))
                                         )
  ),
  TidiedLog = map(FitLog, tidy),
  PredictLog = map(FitLog, augment)
  )

OD_pool_nest %>%
  unnest(PredictLog) %>%
  ggplot() + 
  geom_point(aes(x = E_hours, y = OD_600)) + 
    geom_line(aes(x = E_hours, y = `.fitted`)) + 
 # geom_ribbon(aes(x = E_hours, ymin =  `.fitted` - `.resid`, ymax =  `.fitted` + `.resid`), colour = "grey", fill = "grey") +
  facet_grid(col = vars(MysteryID), rows = vars(Temp_C)) +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = sym("MysteryID"), breaks = NULL, labels = NULL)) +
  scale_y_continuous(sec.axis = sec_axis(~ . , name = sym("Temp_c"), breaks = NULL, labels = NULL)) +
  labs(title = sym(DayGroup), subtitle = sym(DayBench)) +
  theme_bw()

Mu_pool_est <- OD_pool_nest %>% 
  dplyr::select(-c(data, FitLog, PredictLog)) %>%
  unnest(TidiedLog) %>%
  select(-statistic) %>%
  pivot_wider(names_from = term, values_from = c(estimate:p.value))

Mu_pool_est %>%
  ggplot() +
  geom_point(aes(x = MysteryID, y = estimate_Mu)) +
  geom_errorbar(aes(x = MysteryID, ymin = estimate_Mu - std.error_Mu,  ymax = estimate_Mu + std.error_Mu)) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  facet_grid(rows = vars(Temp_C)) +
  scale_y_continuous(sec.axis = sec_axis(~ . , name = sym("Temp_c"), breaks = NULL, labels = NULL)) +
   labs(title = sym(DayGroup), subtitle = sym(DayBench)) +
  theme_bw()

```

# Results & Discussion
