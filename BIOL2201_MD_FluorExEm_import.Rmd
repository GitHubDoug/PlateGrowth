---
title: "Import microbial plate growth data"
author: "Maximilian Berthold, Douglas A. Campbell"
date: "`r format(Sys.Date())`"
output:
  html_document:
    df_print: paged
    code_folding: hide
editor_options: 
  markdown: 
    wrap: sentence
---

This .Rmd imports Molecular Device Fluorescence well plate files, generated using multiple excitation/emission wavelength pairs.
The size of the well plate does not matter; the import creates columns for RowColumn LetterNumber (A01 etc.) for the largest plate type in the list of files.
Import of smaller plate types results in NA in the non-existent RowColumn for that plate.

```{r load libraries, echo=FALSE, message = FALSE, warning = FALSE}
# libraries; Note check actual dependencies
library(tidyverse) #core tidyverse packages
```

Fix File Paths for Import once DataSets accumulate

```{r variable names for file import & processing MOLECULAR DEVICES}
Project <- "BIOL2201"
LabDay <- "TUES"

#File Ex Em nm settings lost from files during import b/c of Header structure

Em <- 680

Ex <- c(440, 520, 620)

#Add colour coding vector
ExNM = (photobiology::w_length2rgb(Ex))
names(ExNM) <- Ex

```

```{r set variables for file import, export}

#Read in from OneDrive; file path is fussy and contains spaces & " - Mount Allison University"
#Remember to force sync to local harddrive b/f attempting import into RStudio

#Currently read in and process each LabDay separately; Alternative could use recursive read in to accumulate files from all LabDays together, then filter upon output?

DataInOneDrive <- paste("~/OneDrive - Mount Allison University/BIOL2201_2024/WI2024Labs/LAB3_MicroGrowth/", LabDay, "_GrowthData", sep = "")

DataOutOneDrive <- paste("~/OneDrive - Mount Allison University/BIOL2201_2024/WI2024Labs/LAB3_MicroGrowth/", "StudentData", sep = "")

file_id <- ".txt"

FileEncodeMD <- "UTF-16LE" 
DelimiterMD <- "\t"
HeaderRowsMD <- 2

#list of files from OneDrive
ExEm_files <- list.files(path = DataInOneDrive, pattern = file_id, full.names = TRUE)

#Import from local OneDrive path does not work from Posit.cloud.  Need to move data files to git tracked project, push to GitHub, pull into Posit.cloud
#List files stored on GitHub
#ExEm_files <- list.files(path = file.path("RawData", "TUES_GrowthData"), pattern = file_id, full.names = TRUE)

ExEm_files
#test for duplicate file names in chl_files
unique(duplicated(ExEm_files))

MetaData <- readxl::read_excel(file.path("~/OneDrive - Mount Allison University/BIOL2201_2024/WI2024Labs/LAB3_MicroGrowth/WellPlateMetaData.xlsx"), sheet = LabDay)

#Local OneDrive MetaData path does not work on Posit.cloud
#MetaData, moved from OneDrive to git tracked project, to github, update with 'pull' from GitHub
#MetaData <- readxl::read_excel(file.path("WellPlateMetaData.xlsx"), sheet = LabDay)

```

```{r guess encoding}
guess_encoding(file = ExEm_files[1])

```

```{r read ExEm files, error = FALSE, message = FALSE, warning = FALSE}

#"id" parameter of read_delim might replace read_delim_plus
#a read function using tidyverse::read_delim that skips a fixed number of header rows, and adds columns to the dataframe containing the filename and the file creation date time.
# 
read_delim_plus <- function(flnm, delimiter, headerrows, fileencode){read_delim(flnm, delim = delimiter,  col_names = TRUE,  skip = headerrows, escape_double = FALSE,  locale = locale(encoding = fileencode), trim_ws = TRUE) |>
    mutate(Filename = flnm)
  }

ExEm_data <- ExEm_files |>
  map_df(~read_delim_plus(flnm = ., delimiter = DelimiterMD,  headerrows = HeaderRowsMD,  fileencode = FileEncodeMD))

```

```{r tidy ExEm_data}
ExEm_data2 <- ExEm_data |>
  select(-c("Temperature(¡C)", "...27")) |>
  separate(Filename, into = c("Path1", "Path2","Path3", "Path4", "Path5", "Path6", "Path7", "Path8","Path9", "Path10", "Path11", "YYYYMMDD", "HHMM","DAY", "LIGHT", "txt"), sep = "([\\/\\_\\.])", remove = FALSE) |>
 select(-c("Path1", "Path2","Path3", "Path4", "Path5", "Path6", "Path7", "Path8","Path9", "Path10", "Path11",  "txt")) |>
  rename(MeasurePt = `...1`)

#Alternate tidy when running on Posit.cloud with GitHub RawData
# ExEm_data2 <- ExEm_data |>
#   select(-c("Temperature(¡C)", "...27")) |>
#   separate(Filename, into = c("Path1", "Path2", "Path3", "YYYYMMDD", "HHMM","DAY", "LIGHT", "txt"), sep = "([\\/\\_\\.])", remove = FALSE) |>
#  select(-c("Path1", "Path2", "Path3", "txt")) |>
#   rename(MeasurePt = `...1`)

#smarter way to code this I am sure
 ExEm_data3 <-  ExEm_data2 |>
   group_by(Filename) |>
   mutate(Ex_nm = case_when(row_number() %in% c(1:5) ~ Ex[1],
                            row_number() %in% c(6:10) ~ Ex[2],
                            row_number() %in% c(11:15)  ~ Ex[3]), .after = MeasurePt) |>
  relocate(c("YYYYMMDD", "HHMM","DAY", "LIGHT")) |>
  unite(YYYYMMDD_HHMM,  YYYYMMDD:HHMM, sep = "_", remove = FALSE) |>
  mutate(YYYYMMDD_HHMM = ymd_hm(YYYYMMDD_HHMM), 
         Ex_nm = as.numeric(Ex_nm)) |>
  filter(!is.na(Ex_nm))
  
```

Tricky file format Ex_nm, Em_nm missing from file format 5 measure points x 3 Ex_nm for each well

Check to make sure E_hours working when more files accumulate

```{r E_hours}
ExEm_data3 <- ExEm_data3 |>
  group_by(DAY, LIGHT) |>
  mutate(E_hours =  as.numeric((YYYYMMDD_HHMM - min(YYYYMMDD_HHMM))) / 3600, .after = YYYYMMDD_HHMM) |>
  ungroup()
```

```{r summarize 5 MeasurePts for each Ex_nm and file}

ExEm_mean <- ExEm_data3 %>%
  group_by(YYYYMMDD_HHMM, E_hours, YYYYMMDD, HHMM, DAY, LIGHT, Ex_nm, Filename) %>%
  summarize(across(A1:D6, mean)) %>%
  ungroup()

```

Export wide format OD_data to OneDrive for Excel Analyses With Just 'HIGH' and 'LOW' plates for each DAY by re-running script.

```{r export DAY csv}

ExEm_mean |>
  filter(Ex_nm == 440) |> #only include Chl data
  arrange(LIGHT, E_hours) |>#order rows by Light and by E_hours
  write_csv(file = file.path(DataOutOneDrive, paste(Project, LabDay, "Chl", ".csv", sep = "_")))

```

More complicated version needed previously.
Need to use old %\>% magrittr::pipe for compatibility; base R \|\> does not work Fix this once data folders accumulate; Day, Bench, Light <https://www.tidyverse.org/blog/2023/05/purrr-walk-this-way/>

```{r}
# OD_data %>%
#   filter(Wavelength_nm == 600) %>%
#   unite("Group_Bench", Group, Bench, sep = "_") %>%
#   arrange(Temp_C) %>%
#   nest(.by = c(Group_Bench)) %>%
#   {walk2(.x = .$data, .y = .$Group_Bench, ~ write_csv(.x, file = file.path("..", "..", "..", "..", DataOneDrive, str_c(.y, ".csv"))))}

```

```{r long format}
ExEm_long <- ExEm_mean |>
  pivot_longer(cols = -c(YYYYMMDD_HHMM:Ex_nm, Filename), names_to = "WELL", values_to = "Fluor") |>
  separate(WELL, into = c("Row", "Col"), sep = 1, remove = FALSE)

ExEm_long |>
  filter(Ex_nm == 440) |>
  ggplot() +
  geom_point(aes(x = E_hours, y = Fluor, colour = LIGHT)) +
  facet_grid(rows = vars(`Row`), cols = vars(`Col`)) + 
  scale_y_continuous(sec.axis = sec_axis(~ . , name = sym("Row"), breaks = NULL, labels = NULL)) +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = sym("Col"), breaks = NULL, labels = NULL)) +
  labs(title = LabDay, subtitle = paste(Ex[1], "_nm", sep = "")) +
  theme_bw()

#ggsave(filename = file.path("Plots", "WellPlateFluorExample.png"))
```

Need DAY, LIGHT, WELL in both MetaData and File data

```{r merge with MetaData}
ExEm_meta <- left_join(ExEm_long, MetaData, by = join_by(DAY, LIGHT, WELL)) |>
  filter(!is.na(SAMPLE)) |>
  filter(Fluor >= 0,
         Fluor <= 1000) #hack fix to remove bad points from 620 nm Ex, 20 h
  
```

```{r test plot}
ExEm_meta |>
  filter(Ex_nm == 440) |>
  ggplot() +
  geom_point(aes(x = E_hours, y = Fluor, colour = INITIAL)) +
  #scale_colour_manual(values = ExNM) +
  facet_grid(rows = vars(SAMPLE), cols = vars(LIGHT)) +
  labs(title = LabDay, subtitle = paste(Ex[1], "_nm"))+
  theme_bw()

ExEm_meta |>
  ggplot() +
  geom_point(aes(x = E_hours, y = Fluor, colour = LIGHT)) +
  #scale_colour_manual(values = ExNM) +
  facet_grid(rows = vars(SAMPLE), cols = vars(Ex_nm)) +
  labs(title = LabDay) +
  theme_bw()
```

```{r save ExEm_meta, echo=FALSE}

ExEm_meta |>
  saveRDS(file.path(DataOutOneDrive, paste(Project, LabDay, "ExEm_meta.Rds", sep = "_"), fsep = .Platform$file.sep))

```

#<https://stackoverflow.com/questions/72906809/read-and-write-excel-and-csv-files-from-sharepoint-via-r>

```{r export OD600.csv to shared OneDrive folder}
#OD600Meta |>
  # #select(-c(Media_mL, Innoc_mL, Row, Col, logOD_600)) |>
  # pivot_wider(names_from = c(Well, Wavelength_nm, MysteryID), values_from = c(OD)) |>
   #pivot_wider(names_from = c(Well, Wavelength_nm), values_from = c(OD)) |>
  # arrange(Temp_C) |>
  # unite("Group_Bench", Group, Bench, sep = "_") |>
  # nest(.by = c(Group_Bench)) |>
  # {walk2(.x = .$data, .y = .$Group_Bench, ~ write_csv(.x, file = file.path("..", "..", "..", "..", DataOneDrive, str_c(.y, ".csv"))))}

```
